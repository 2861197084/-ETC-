#!/usr/bin/env python3
"""
Inject synthetic pass records to trigger flow peak alert.

Usage:
    # ä» Docker å®¹å™¨å†…è¿è¡Œ
    docker compose run --rm data-service python -m scripts.inject_flow_peak --checkpoint CP001 --count 500
    
    # æˆ–æœ¬åœ°è¿è¡Œ (éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡)
    python -m scripts.inject_flow_peak --checkpoint CP001 --count 500
"""

from __future__ import annotations

import argparse
import logging
import os
import random
import sys
import time
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Optional

# åŒ—äº¬æ—¶åŒº UTC+8
BEIJING_TZ = timezone(timedelta(hours=8))

import pymysql
import requests

# Ensure "app" is importable when running as module.
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config import settings
from app.kafka_producer import producer


logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)

TIME_FORMAT = "%Y-%m-%d %H:%M:%S"

# ç«™ç‚¹ä¿¡æ¯
CHECKPOINTS = {
    "CP001": ("ç¢å®å¡1(104çœé“)", "ç¢å®å¿"),
    "CP002": ("æ²›å¿å¡2(311å›½é“)", "æ²›å¿"),
    "CP003": ("æ²›å¿å¡3(å¾ä¸°é«˜é€Ÿ)", "æ²›å¿"),
    "CP004": ("æ²›å¿å¡4(å®¿æ–°é«˜é€Ÿ)", "æ²›å¿"),
    "CP005": ("æ–°æ²‚å¡1(205å›½é“)", "æ–°æ²‚å¸‚"),
    "CP006": ("æ–°æ²‚å¡2(æ–°é•¿é“è·¯)", "æ–°æ²‚å¸‚"),
    "CP007": ("æ–°æ²‚å¡3(323çœé“)", "æ–°æ²‚å¸‚"),
    "CP008": ("é‚³å·å¡1(250çœé“)", "é‚³å·å¸‚"),
    "CP009": ("é‚³å·å¡2(310å›½é“)", "é‚³å·å¸‚"),
    "CP010": ("é‚³å·å¡4(é‚³æ–°é«˜é€Ÿ)", "é‚³å·å¸‚"),
    "CP011": ("è´¾æ±ªå¡5(äº¬æ²ªé«˜é€Ÿ)", "è´¾æ±ªåŒº"),
    "CP012": ("è´¾æ±ªå¡1(206å›½é“)", "è´¾æ±ªåŒº"),
    "CP013": ("è´¾æ±ªå¡2(310å›½é“)", "è´¾æ±ªåŒº"),
    "CP014": ("è¿äº‘æ¸¯å¡2(310å›½é“)", "è¿äº‘æ¸¯å¸‚"),
    "CP015": ("å®¿è¿å¡1(äº¬æ²ªé«˜é€Ÿ)", "å®¿è¿å¸‚"),
    "CP016": ("å®¿è¿å¡2(å¾å®¿å¿«é€Ÿ)", "å®¿è¿å¸‚"),
    "CP017": ("é“œå±±å¡1(206å›½é“)", "é“œå±±åŒº"),
    "CP018": ("é“œå±±å¡2(104å›½é“)", "é“œå±±åŒº"),
    "CP019": ("é“œå±±å¡4(å¾æµé«˜é€Ÿ)", "é“œå±±åŒº"),
}

PLATE_PREFIXES = ["è‹C", "è‹A", "è‹B", "é²B", "è±«N", "çš–A", "è‹D", "è‹E"]
DIRECTIONS = ["è¿›åŸ", "å‡ºåŸ"]
PLATE_TYPES = ["01", "02", "52"]  # å°å‹æ±½è½¦, å¤§å‹æ±½è½¦, æ–°èƒ½æº
CAR_BRANDS = ["å¤§ä¼—æœ—é€¸", "ä¸°ç”°å¡ç½—æ‹‰", "æœ¬ç”°æ€åŸŸ", "åˆ«å…‹è‹±æœ—", "æ—¥äº§è½©é€¸", "ç°ä»£é¢†åŠ¨", "ç¦ç‰¹ç¦å…‹æ–¯"]


def get_simulated_time_and_window(time_api: str) -> tuple[datetime, datetime, datetime]:
    """ä»åç«¯è·å–æ¨¡æ‹Ÿæ—¶é—´å’Œå½“å‰çª—å£"""
    try:
        resp = requests.get(time_api, timeout=5)
        resp.raise_for_status()
        payload = resp.json()
        data = payload.get("data", {})
        sim = data.get("simulatedTime")
        window_start = data.get("windowStart")
        window_end = data.get("windowEnd")
        if not sim:
            raise ValueError("missing data.simulatedTime")
        sim_dt = datetime.strptime(sim, TIME_FORMAT)
        start_dt = datetime.strptime(window_start, TIME_FORMAT) if window_start else sim_dt - timedelta(minutes=5)
        end_dt = datetime.strptime(window_end, TIME_FORMAT) if window_end else sim_dt
        return sim_dt, start_dt, end_dt
    except Exception as e:
        logger.warning(f"Failed to get simulated time: {e}, using current time")
        now = datetime.now(BEIJING_TZ)
        return now, now - timedelta(minutes=5), now


def mysql_conn():
    """åˆ›å»º MySQL è¿æ¥ (é€šè¿‡ ShardingSphere)"""
    host = os.getenv("MYSQL_HOST", "shardingsphere")
    port = int(os.getenv("MYSQL_PORT", "3307"))
    user = os.getenv("MYSQL_USER", "root")
    password = os.getenv("MYSQL_PASSWORD", "root")
    return pymysql.connect(
        host=host,
        port=port,
        user=user,
        password=password,
        database="etc",
        charset="utf8mb4",
        cursorclass=pymysql.cursors.DictCursor,
        autocommit=False,
    )


def generate_plate() -> str:
    """ç”Ÿæˆéšæœºè½¦ç‰Œ"""
    prefix = random.choice(PLATE_PREFIXES)
    num = ''.join(random.choices('0123456789ABCDEFGHJKLMNPQRSTUVWXYZ', k=5))
    return f"{prefix}{num}"


def inject_flow_peak(checkpoint_id: str, count: int, time_api: str, use_kafka: bool = False):
    """æ³¨å…¥è½¦æµé‡é«˜å³°æ•°æ®"""
    
    if checkpoint_id not in CHECKPOINTS:
        logger.error(f"Unknown checkpoint: {checkpoint_id}")
        logger.info(f"Available checkpoints: {list(CHECKPOINTS.keys())}")
        return False
    
    cp_name, cp_district = CHECKPOINTS[checkpoint_id]
    
    # è·å–æ¨¡æ‹Ÿæ—¶é—´å’Œå½“å‰çª—å£
    sim_time, window_start, window_end = get_simulated_time_and_window(time_api)
    logger.info(f"ğŸ“ ç›®æ ‡ç«™ç‚¹: {cp_name} ({checkpoint_id})")
    logger.info(f"â° æ¨¡æ‹Ÿæ—¶é—´: {sim_time}")
    logger.info(f"ğŸ“ å½“å‰çª—å£: {window_start} ~ {window_end}")
    logger.info(f"ğŸ“Š æ³¨å…¥æ•°é‡: {count} æ¡")
    
    # è®¡ç®—éœ€è¦çš„è½¦æµé‡
    # maxCapacity = 4è½¦é“ Ã— 800è¾†/å°æ—¶ = 3200è¾†/å°æ—¶
    # è¦è§¦å‘30%é˜ˆå€¼ï¼Œéœ€è¦ 3200 Ã— 0.3 = 960è¾†/å°æ—¶
    # 5åˆ†é’Ÿçª—å£ = 960 / 12 = 80æ¡è®°å½•
    # è¦è§¦å‘70%é˜ˆå€¼ï¼Œéœ€è¦ 3200 Ã— 0.7 / 12 = 187æ¡/çª—å£
    logger.info(f"ğŸ’¡ æç¤º: è¦è§¦å‘30%é˜ˆå€¼éœ€è¦~80æ¡/çª—å£, 70%éœ€è¦~187æ¡/çª—å£")
    
    # è¦†ç›–å½“å‰çª—å£å’Œæœªæ¥5ä¸ªçª—å£ï¼ˆå…±30åˆ†é’Ÿï¼‰ï¼Œç¡®ä¿æ•°æ®èƒ½è¢«æŸ¥è¯¢åˆ°
    total_window_seconds = 30 * 60  # 30åˆ†é’Ÿ
    
    records = []
    for i in range(count):
        # åœ¨å½“å‰çª—å£å¼€å§‹åˆ°æœªæ¥20åˆ†é’Ÿå†…éšæœºåˆ†å¸ƒ
        offset_seconds = random.randint(0, total_window_seconds - 1)
        pass_time = window_start + timedelta(seconds=offset_seconds)
        
        plate = generate_plate()
        gcxh = f"PEAK{int(time.time() * 1000) % 100000000}{i:05d}"
        
        record = {
            "gcxh": gcxh,
            "xzqhmc": cp_district,
            "kkmc": cp_name,
            "fxlx": random.choice(DIRECTIONS),
            "gcsj": pass_time.strftime(TIME_FORMAT),
            "hpzl": random.choice(PLATE_TYPES),
            "hp": plate,
            "clppxh": random.choice(CAR_BRANDS),
            "plate_hash": hash(plate) & 0x7FFFFFFF,
            "checkpoint_id": checkpoint_id,
        }
        records.append(record)
    
    if use_kafka:
        # é€šè¿‡ Kafka å‘é€
        logger.info("ğŸš€ é€šè¿‡ Kafka å‘é€æ•°æ®...")
        producer.connect()
        for i, rec in enumerate(records):
            producer.send(rec, key=rec.get('hp'))
            if (i + 1) % 100 == 0:
                producer.flush()
                logger.info(f"  å·²å‘é€ {i + 1}/{count}")
        producer.flush()
        producer.close()
    else:
        # ç›´æ¥å†™å…¥ MySQL
        logger.info("ğŸš€ ç›´æ¥å†™å…¥ MySQL...")
        conn = mysql_conn()
        try:
            with conn.cursor() as cur:
                sql = """
                    INSERT INTO pass_record (gcxh, xzqhmc, kkmc, fxlx, gcsj, hpzl, hp, clppxh, plate_hash, checkpoint_id)
                    VALUES (%(gcxh)s, %(xzqhmc)s, %(kkmc)s, %(fxlx)s, %(gcsj)s, %(hpzl)s, %(hp)s, %(clppxh)s, %(plate_hash)s, %(checkpoint_id)s)
                """
                batch_size = 100
                for i in range(0, len(records), batch_size):
                    batch = records[i:i + batch_size]
                    cur.executemany(sql, batch)
                    conn.commit()
                    logger.info(f"  å·²å†™å…¥ {min(i + batch_size, count)}/{count}")
        finally:
            conn.close()
    
    logger.info(f"âœ… å®Œæˆï¼å·²æ³¨å…¥ {count} æ¡è®°å½•åˆ° {cp_name}")
    logger.info(f"ğŸ’¡ ç°åœ¨åˆ·æ–°å¤§å±é¡µé¢ï¼Œåº”è¯¥èƒ½çœ‹åˆ°è½¦æµé‡é«˜å³°å‘Šè­¦")
    return True


def main() -> int:
    parser = argparse.ArgumentParser(description="Inject data to trigger flow peak alert.")
    parser.add_argument("--checkpoint", "-c", required=True, help="Checkpoint ID (e.g. CP001)")
    parser.add_argument("--count", "-n", type=int, default=500, help="Number of records to inject (default: 500)")
    parser.add_argument("--kafka", action="store_true", help="Send via Kafka instead of direct MySQL insert")
    parser.add_argument("--time-api", default=os.getenv("BACKEND_TIME_API", "http://backend:8080/api/time"), help="Time API endpoint")
    parser.add_argument("--list", "-l", action="store_true", help="List available checkpoints")
    
    args = parser.parse_args()
    
    if args.list:
        print("\nå¯ç”¨ç«™ç‚¹åˆ—è¡¨:")
        print("-" * 50)
        for code, (name, district) in sorted(CHECKPOINTS.items()):
            print(f"  {code}: {name} ({district})")
        print()
        return 0
    
    success = inject_flow_peak(
        checkpoint_id=args.checkpoint,
        count=args.count,
        time_api=args.time_api,
        use_kafka=args.kafka,
    )
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
