#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETC å®æ—¶æ•°æ®ç”Ÿæˆå™¨

ä»…å†™å…¥ Kafkaï¼Œç”± Flink ä½œä¸šå¤„ç†åç»­ï¼š
- DataSyncJob: Kafka -> MySQL + HBase åŒå†™
- CounterJob: Kafka -> Redis è®¡æ•°å™¨æ›´æ–°
- å…¶ä»–ä½œä¸š: å¥—ç‰Œæ£€æµ‹ã€è¿ç« æ£€æµ‹ã€æµé‡ç»Ÿè®¡ç­‰

ç”¨æ³•:
    python realtime_generator.py                # æ¯ç§’10æ¡
    python realtime_generator.py --rate 50      # æ¯ç§’50æ¡
"""

import json
import random
import string
import argparse
import signal
import time
from datetime import datetime
from typing import List

from kafka import KafkaProducer

# ============== é…ç½® ==============

KAFKA_CONFIG = {
    'bootstrap_servers': ['localhost:19092'],
    'topic': 'etc-pass-records'  # ä¸ Flink FlinkConfig.KAFKA_TOPIC_PASS_RECORDS ä¿æŒä¸€è‡´
}

# 19ä¸ªå¡å£
CHECKPOINTS = [
    {"id": "CP001", "name": "è‹çš–ç•Œ1(104çœé“)", "district": "ç¢å®å¿"},
    {"id": "CP002", "name": "è‹çš–ç•Œ2(311å›½é“)", "district": "é“œå±±åŒº"},
    {"id": "CP003", "name": "è‹çš–ç•Œ3(å¾æ˜é«˜é€Ÿ)", "district": "é“œå±±åŒº"},
    {"id": "CP004", "name": "è‹çš–ç•Œ4(å®¿æ–°é«˜é€Ÿ)", "district": "ç¢å®å¿"},
    {"id": "CP005", "name": "è‹çš–ç•Œ5(å¾æ·®é«˜é€Ÿ)", "district": "æ²›å¿"},
    {"id": "CP006", "name": "è‹çš–ç•Œ6(æ–°æ‰¬é«˜é€Ÿ)", "district": "æ–°æ²‚å¸‚"},
    {"id": "CP007", "name": "è‹é²ç•Œ1(206å›½é“)", "district": "æ²›å¿"},
    {"id": "CP008", "name": "è‹é²ç•Œ2(104å›½é“)", "district": "é‚³å·å¸‚"},
    {"id": "CP009", "name": "è‹é²ç•Œ3(äº¬å°é«˜é€Ÿ)", "district": "è´¾æ±ªåŒº"},
    {"id": "CP010", "name": "è‹é²ç•Œ4(æ£åº„è¿æ¥çº¿)", "district": "é‚³å·å¸‚"},
    {"id": "CP011", "name": "è‹é²ç•Œ5(äº¬æ²ªé«˜é€Ÿ)", "district": "é‚³å·å¸‚"},
    {"id": "CP012", "name": "è‹é²ç•Œ6(æ²‚æ²³è·¯)", "district": "æ–°æ²‚å¸‚"},
    {"id": "CP013", "name": "è¿äº‘æ¸¯ç•Œ1(å¾è¿é«˜é€Ÿ)", "district": "é‚³å·å¸‚"},
    {"id": "CP014", "name": "è¿äº‘æ¸¯ç•Œ2(310å›½é“)", "district": "é‚³å·å¸‚"},
    {"id": "CP015", "name": "å®¿è¿ç•Œ1(å¾å®¿é«˜é€Ÿ)", "district": "é“œå±±åŒº"},
    {"id": "CP016", "name": "å®¿è¿ç•Œ2(å¾å®¿å¿«é€Ÿ)", "district": "é“œå±±åŒº"},
    {"id": "CP017", "name": "å®¿è¿ç•Œ3(104å›½é“)", "district": "ç¢å®å¿"},
    {"id": "CP018", "name": "å®¿è¿ç•Œ4(æ–°æ‰¬é«˜é€Ÿ)", "district": "ç¢å®å¿"},
    {"id": "CP019", "name": "å®¿è¿ç•Œ5(å¾ç›é«˜é€Ÿ)", "district": "ç¢å®å¿"},
]

PLATE_PREFIXES = ["è‹C", "è‹C", "è‹C", "è‹C", "è‹A", "è‹B", "è‹N", "è‹H", "é²Q", "é²A", "çš–L", "çš–A", "è±«N"]
VEHICLE_TYPES = ["å°å‹å®¢è½¦", "å°å‹å®¢è½¦", "å°å‹å®¢è½¦", "ä¸­å‹å®¢è½¦", "å°å‹è´§è½¦", "å¤§å‹è´§è½¦"]
PLATE_TYPES = ["å°å‹æ±½è½¦å·ç‰Œ", "å°å‹æ±½è½¦å·ç‰Œ", "å°å‹æ±½è½¦å·ç‰Œ", "å¤§å‹æ±½è½¦å·ç‰Œ", "æ–°èƒ½æºå°å‹æ±½è½¦å·ç‰Œ"]
DIRECTIONS = ["è¿›åŸ", "å‡ºåŸ"]


class RealtimeGenerator:
    def __init__(self, rate: int = 10):
        self.rate = rate
        self.running = False
        self.id_counter = int(time.time() * 1000000)
        self.gcxh_counter = 400000000000
        
        self.stats = {'generated': 0, 'sent': 0, 'errors': 0, 'start_time': None}
        self.kafka_producer = None
        
        self._connect()
    
    def _connect(self):
        try:
            self.kafka_producer = KafkaProducer(
                bootstrap_servers=KAFKA_CONFIG['bootstrap_servers'],
                value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8'),
                acks='all',
                retries=3
            )
            print(f"âœ… Kafka å·²è¿æ¥: {KAFKA_CONFIG['bootstrap_servers']}")
            print(f"   Topic: {KAFKA_CONFIG['topic']}")
        except Exception as e:
            print(f"âŒ Kafka è¿æ¥å¤±è´¥: {e}")
            exit(1)
    
    def _generate_plate(self) -> str:
        prefix = random.choice(PLATE_PREFIXES)
        suffix = ''.join([
            random.choice(string.ascii_uppercase),
            random.choice(string.ascii_uppercase),
            str(random.randint(0, 9)),
            str(random.randint(0, 9)),
            str(random.randint(0, 9))
        ])
        return f"{prefix}{suffix}"
    
    def generate_record(self) -> dict:
        """ç”Ÿæˆä¸€æ¡é€šè¡Œè®°å½•ï¼ˆä¸ Flink PassRecordEvent ç»“æ„å¯¹åº”ï¼‰"""
        checkpoint = random.choice(CHECKPOINTS)
        plate = self._generate_plate()
        
        self.id_counter += 1
        self.gcxh_counter += 1
        
        # ä¸ Flink PassRecordEvent å­—æ®µå¯¹åº”
        return {
            'id': self.id_counter,
            'gcxh': f"G320300{self.gcxh_counter}",
            'xzqhmc': checkpoint['district'],
            'kkmc': checkpoint['name'],
            'fxlx': random.choice(DIRECTIONS),
            'gcsj': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'hpzl': random.choice(PLATE_TYPES),
            'hp': plate,
            'clppxh': random.choice(VEHICLE_TYPES),
            'checkpointId': checkpoint['id'],
            'eventTime': int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
        }
    
    def send_to_kafka(self, records: List[dict]):
        """å‘é€åˆ° Kafkaï¼Œç”± Flink æ¶ˆè´¹å¤„ç†"""
        try:
            for r in records:
                self.kafka_producer.send(KAFKA_CONFIG['topic'], value=r)
            self.kafka_producer.flush()
            self.stats['sent'] += len(records)
        except Exception as e:
            print(f"âŒ Kafka å‘é€å¤±è´¥: {e}")
            self.stats['errors'] += 1
    
    def run(self):
        self.running = True
        self.stats['start_time'] = datetime.now()
        
        print(f"\nğŸš€ å¼€å§‹ç”Ÿæˆæ•°æ® (é€Ÿç‡: {self.rate} æ¡/ç§’)")
        print("   æ•°æ®æµ: Python -> Kafka -> Flink -> MySQL/HBase/Redis")
        print("   æŒ‰ Ctrl+C åœæ­¢\n")
        
        signal.signal(signal.SIGINT, lambda s, f: setattr(self, 'running', False))
        signal.signal(signal.SIGTERM, lambda s, f: setattr(self, 'running', False))
        
        batch_size = max(1, self.rate // 10)
        interval = 0.1
        
        while self.running:
            try:
                start = time.time()
                records = [self.generate_record() for _ in range(batch_size)]
                
                self.send_to_kafka(records)
                self.stats['generated'] += len(records)
                
                if self.stats['generated'] % (self.rate * 10) < batch_size:
                    elapsed = (datetime.now() - self.stats['start_time']).total_seconds()
                    rate = self.stats['sent'] / elapsed if elapsed > 0 else 0
                    print(f"ğŸ“Š å·²å‘é€: {self.stats['sent']:,} æ¡ | é€Ÿç‡: {rate:.1f}/s | Kafkaå¾…å¤„ç†")
                
                sleep_time = max(0, interval - (time.time() - start))
                if sleep_time > 0:
                    time.sleep(sleep_time)
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
                self.stats['errors'] += 1
                time.sleep(1)
        
        print(f"\nâœ… åœæ­¢! å…±å‘é€ {self.stats['sent']:,} æ¡åˆ° Kafka")
        if self.kafka_producer:
            self.kafka_producer.close()


def main():
    parser = argparse.ArgumentParser(description='ETC å®æ—¶æ•°æ®ç”Ÿæˆå™¨ï¼ˆå†™å…¥Kafkaï¼‰')
    parser.add_argument('--rate', type=int, default=10, help='æ¯ç§’è®°å½•æ•° (é»˜è®¤: 10)')
    args = parser.parse_args()
    
    print("=" * 55)
    print("      ETC å®æ—¶æ•°æ®ç”Ÿæˆå™¨ (Kafka -> Flink æ¶æ„)")
    print("=" * 55)
    print(f"  é€Ÿç‡: {args.rate} æ¡/ç§’")
    print(f"  Kafka: {KAFKA_CONFIG['bootstrap_servers']}")
    print(f"  Topic: {KAFKA_CONFIG['topic']}")
    print("=" * 55)
    print("\nğŸ“Œ Flink ä½œä¸šè´Ÿè´£ï¼š")
    print("   - DataSyncJob: åŒå†™ MySQL + HBase")
    print("   - CounterJob: æ›´æ–° Redis è®¡æ•°å™¨")
    print("   - ClonePlateDetectJob: å¥—ç‰Œæ£€æµ‹")
    print("   - TrafficFlowJob: æµé‡ç»Ÿè®¡")
    print()
    
    generator = RealtimeGenerator(rate=args.rate)
    generator.run()


if __name__ == '__main__':
    main()
