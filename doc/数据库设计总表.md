# ETC 大数据平台 - 存储结构（与实现一致）

> 以 `infra/mysql/init/*.sql`、`infra/hbase/init/*.hbase` 与当前后端/脚本实际读写为准。

---

## 1. MySQL（热数据与业务表）

### 1.1 热数据（分片表 + 视图）

- `pass_record`：ShardingSphere 逻辑表（后端/Flink 通过 Proxy 访问）。
- `mysql0/mysql1`：实际分片库；物理表为 `pass_record_0` / `pass_record_1`（字段来自 CSV：`GCXH,XZQHMC,KKMC,FXLX,GCSJ,HPZL,HP,CLPPXH`，并补齐 `plate_hash`、`checkpoint_id`）。

> 写入来源：Flink `MySqlStorageJob`（Kafka → ShardingSphere Proxy → MySQL 分片）。

### 1.2 基础表（广播表）

位于 `infra/mysql/init/00-base-tables.sql`：

- `checkpoint`：19 个卡口维表（`code=CP001..CP019`）
- `checkpoint_flow`：卡口流量（实时/分钟级聚合使用）
- `violation`：违章记录
- `clone_plate_detection`：套牌检测记录
- `appeal`：申诉记录
- `sys_user` / `sys_role` / `vehicle`：演示用账户/车辆表

### 1.3 统计/分析表（可选）

位于 `infra/mysql/init/02-stats-schema.sql`，用于扩展统计与分析能力（如 `stats_*`、`analysis_*`、`bill`、`alert`、`query_history`）。

---

## 2. HBase（历史与归档明细）

初始化脚本：`infra/hbase/init/create-tables.hbase`

- 表：`etc:pass_record`
- 列族：`d`
- 主要列（脚本/Flink 写入）：`d:hp`、`d:gcsj`、`d:kkmc`、`d:checkpoint_id`、`d:xzqhmc`、`d:fxlx`、`d:hpzl`、`d:clppxh`

> 写入来源：
> - 历史：`data-service/scripts/import_to_hbase.py`
> - 实时归档：Flink `HBaseStorageJob`

---

## 3. Redis（统计汇总）

当前实现使用以下 key（前缀 `etc:stats:`）：

- 历史导入统计（由 `import_to_hbase.py` 写入）
  - `etc:stats:history:pass_record:total`（STRING，总量）
  - `etc:stats:history:pass_record:by_checkpoint`（HASH，按 `CPxxx` 计数）
  - `etc:stats:history:pass_record:last_import`（STRING，最后一次导入时间）
- 热数据统计（由后端定时任务写入，带短 TTL）
  - `etc:stats:hot:mysql7d:pass_record:total`（STRING）
  - `etc:stats:hot:mysql7d:pass_record:today`（STRING）
  - `etc:stats:hot:mysql7d:pass_record:today:by_checkpoint`（HASH）
