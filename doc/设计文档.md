# ETC 高速公路大数据平台 - 系统设计

> 本文档描述当前仓库的**实际实现**：模块划分、数据流、存储分层、虚拟时间与查询路由。接口细节以 `doc/API接口文档.md` 为准。

---

## 1. 模块与职责

- `frontend/`：Vue 3 指挥舱与查询中心（右上角展示**虚拟时间**）。
- `backend/`：Spring Boot 单体后端，提供地图/实时/查询/时间模拟等 REST API，并负责：
  - MySQL 热数据统计聚合到 Redis
  - MySQL 近 7 天热数据定时清理（按虚拟时间）
- `data-service/`：脚本化数据接入：
  - `import_to_hbase.py`：导入 2023-12 历史 CSV 到 HBase，并写入 Redis 历史统计
  - `realtime_simulator.py`：按虚拟时间窗口从 2024-01 CSV 读数并发送到 Kafka
- `flink-jobs/`：Flink 作业：
  - `MySqlStorageJob`：Kafka → ShardingSphere Proxy → MySQL 分片（逻辑表 `pass_record`）
  - `HBaseStorageJob`：Kafka → HBase（归档 `etc:pass_record`）
  - `ClonePlateDetectorJob`：Kafka → ShardingSphere Proxy（套牌告警）

---

## 2. 数据流与存储分层

### 2.1 历史数据（2023-12）

`CSV → import_to_hbase.py → HBase(etc:pass_record) → Redis(历史总量/按卡口统计)`

### 2.2 实时数据（2024-01）

`CSV → realtime_simulator.py → Kafka(etc-pass-records) → Flink → ShardingSphere Proxy → MySQL(热数据分片) + HBase(归档)`

### 2.3 查询路由

- 近 7 天：ShardingSphere 逻辑表 `pass_record`（底层为 `mysql0/mysql1` 的 `pass_record_0/1`）
- 历史范围：HBase 表 `etc:pass_record`
- 统计汇总：Redis（后端定时刷新热数据统计；历史导入写入历史统计）

---

## 3. 虚拟时间

- 基准时间：`2024-01-01 00:00:00`
- 时间加速：`1s(真实) = 5min(虚拟)`
- 后端时间 API：`/api/time/*`
- `realtime_simulator.py` 以 `/api/time` 返回的 `windowStart/windowEnd` 作为“当前 5 分钟窗口”读取 CSV 并推送 Kafka。

---

## 4. 卡口命名与编码

原始 CSV 字段 `KKMC` 为“长命名”。系统内部统一使用 `CP001..CP019` 作为卡口编码：

- `data-service` / `flink-jobs` 会把 `KKMC` 映射为 `checkpointId` 并落库（MySQL/HBase）。
- `2023-12` 的 `KKMC` 全月共有 20 个唯一值，其中 2 个仅差“江苏省”前缀，实际表示同一卡口；已统一映射到同一 `CPxxx`。

---

## 5. 热数据保留策略

- MySQL 热数据默认保留 7 天（按虚拟时间计算），后端通过 ShardingSphere Proxy 定时按批次清理逻辑表 `pass_record`，配置位于 `backend/src/main/resources/application.yml` 的 `etc.retention.*`。
